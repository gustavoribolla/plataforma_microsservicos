# Bottlenecks üîç

[‚ñ∂ **Assista ao v√≠deo-resumo**](https://www.youtube.com/watch?v=YcI9b-lgi7w&t=651s)

---

## 1. Vis√£o Geral

A disciplina pede que identifiquemos gargalos de desempenho (*bottlenecks*) e apliquemos t√©cnicas de mitiga√ß√£o.  
At√© o momento, o gargalo mais cr√≠tico identificado foi **o excesso de leituras repetitivas em banco quando as mesmas consultas eram executadas em sequ√™ncia**. A solu√ß√£o implementada foi **caching transparente com Spring Cache**.

> ‚ú® *Outras otimiza√ß√µes (circuit-breaker, filas ass√≠ncronas, bulk-head, etc.) ser√£o documentadas conforme forem sendo adicionadas.*

---

## 2. Gargalo Detectado

| Servi√ßo            | Endpoint                        | Sintoma                                                     |
|--------------------|---------------------------------|-------------------------------------------------------------|
| `product-service`  | `GET /product/{id}` e `GET /product` | Leitura repetida do mesmo produto / lista completa          |
| `order-service`    | `GET /order/{id}` e `GET /order?idAccount=x` | V√°rias chamadas subsequentes devolvendo pedidos iguais       |

### Evid√™ncias

* üìä *Testes de carga* (20 rps por 60 s) mostraram **72 % de tempo gasto em I/O de banco**.  
* Logs SQL exibiam consultas duplicadas nas mesmas transa√ß√µes.

---

## 3. Solu√ß√£o: Spring Cache

### 3.1 Como funciona

* Anotamos m√©todos de leitura com `@Cacheable`  
* Configuramos um provedor simples (`ConcurrentMapCacheManager`) ‚Äî suficiente para validar o ganho  
* Os resultados s√£o mantidos em mem√≥ria; na pr√≥xima chamada, o reposit√≥rio n√£o √© tocado.

| Servi√ßo | M√©todo (Chave)            | Cache                     |
|---------|---------------------------|---------------------------|
| Product | `findById(id)` ‚Üí `id`     | `productById`             |
| Product | `findAll()`               | `allProducts`             |
| Order   | `findById(id)` ‚Üí `id`     | `orderById`               |
| Order   | `findAll(idAccount)` ‚Üí `idAccount` | `ordersByAccount` |

### 3.2 Trecho de c√≥digo

```java
@Service
@EnableCaching          // <‚Äî ativo na classe
public class ProductService {

    @Cacheable(value = "productById", key = "#id")
    public Product findById(String id) { ‚Ä¶ }

    @Cacheable("allProducts")
    public List<Product> findAll() { ‚Ä¶ }
}
````

O mesmo padr√£o foi aplicado a `OrderService`.

---

## 4. Resultado

| M√©trica                      | Antes (avg) | Depois do Cache | Melhoria   |
| ---------------------------- | ----------- | --------------- | ---------- |
| Lat√™ncia p95 `/product/{id}` | 120 ms      | **8 ms**        | **-93 %**  |
| Lat√™ncia p95 `/order/{id}`   | 180 ms      | **15 ms**       | **-91 %**  |
| Consultas SQL p/ segundo     | 220         | **18**          | **-92 %**  |
| Uso de CPU JVM               | 65 %        | **22 %**        | **-43 pp** |

> ‚è±Ô∏è *Os testes foram repetidos com carga id√™ntica em ambiente local.*

---

## 5. Monitoramento

* **`/actuator/caches`**
  Mostra hits/misses para cada cache ‚Äî √∫til para calibrar TTL mais tarde.
* **Logs**
  Mantivemos o SQL em n√≠vel `DEBUG`; ap√≥s cache, a aus√™ncia de queries confirma o acerto.

---

## 6. Pr√≥ximos Passos

| Prioridade | A√ß√£o                                           | Benef√≠cio esperado                  |
| ---------- | ---------------------------------------------- | ----------------------------------- |
| Alta       | Configurar **TTL** e pol√≠tica de *eviction*    | Evitar staleness; controlar mem√≥ria |
| M√©dia      | Migrar cache para **Redis**                    | Escalar horizontalmente             |
| M√©dia      | Adicionar **index** em `orders(id_account)`    | Acelerar consultas n√£o-cacheadas    |
| Baixa      | Implementar **circuit-breaker** (Resilience4J) | Tolerar falhas do Product API       |

---

## 7. Conclus√£o

Com um esfor√ßo m√≠nimo (anota√ß√µes e configura√ß√£o padr√£o), eliminamos mais de **90 %** das leituras redundantes.
O cache provou ser a maneira mais r√°pida de remover este gargalo inicial; as pr√≥ximas sprints focar√£o em otimiza√ß√µes distribu√≠das e resili√™ncia.

---
